**Task Prompt:**
	Create a “SensorPOC” agent, a program unit, that would generate some synthetics data (to keep  it simple, random data in loop) and writes as a CSV file.  
	File format: 
	FileName: SensorName_YYYYMMDD_Counter.csv 
	Headers: TimeStamp, SensorId, SensorName, Key1, Value1, Key2, Value2 
	Sample filename: SensorPOC_20250303_100.csv 
	Sample values: 
	TimeStamp, SensorId, SensorName, Key1, Value1, Key2, Value2 
	2025-03-03T15:30:05.000Z, 100, SensorPOC, Lat, 1.00, Lon, 5.20 
	2025-03-03T15:30:06.000Z, 100, SensorPOC, Lat, 1.50, Lon, 5.25 
	2025-03-03T15:30:07.000Z, 100, SensorPOC, Lat, 1.30, Lon, 5.50 
	… 
	SensorPOC would generate above file and writes to it with datapoints.  
	When the entries count reaches 100, it would close the file and create new one, For example,  
	SensorPOC_20250303_101 
	And starts to write it. 
	For simplicity, SensorPOC would emit an entry or datapoint every second. 
	Value1 and 2 can be some random double values (if needed, can also include empty values assuming  no reading) 
	Let’s create a ingest service agent “IngesterPOC”, that would consume the csv files that were  generated by “SensorPOC” agent. 
	IngesterPOC would read files, for example, SensorPOC_20250303_100.csv and writes it to a timeseries  database. For simplicity, IngesterPOC would read the entries, and writes a log entry of what it read. 
	Log entry format: 
	{ 
	 “TimeStamp”: “2025-03-03T15:31:05.000Z”, 
	 “Source”: “SensorPOC”, 
	 “FileName” : “SensorPOC_20250303_101.csv”, 
	 “SuccessEntries”: 100, // entries that have values 
	 “FailedEntries”: 0, //entries that have empty/null values
	 “Errors”: “” 
	} 
	Create above 2 processes/programs. (Either in C# or python) 
	Do containerized it (if possible). 
	Let’s say, if we launch the POC as docker compose (or shell scripts, or other means), it will start 2  processes. 
	SensorPOC starts to generate csv files, and IngestPOC waits for the generated file and reads it. 

**Pseudo:**
	Class- Program.cs
		//Run methods form other classes
	
		Methods called
			SensorPOC.writefile
			SensorPOC.close
			IngestorPOC.readfile
			IngestorPOC.close
	
	Class- SensorPOC.cs
		//Record and write data every second to a CSV file
		//When 100 lines is reached on the CSV file, close and open new file
		//Create random numbers for Lat and Lon to be recorded
	
		Var
			file.name //SensorName_YYYYMMDD_Counter.csv
			file.line.counter
			timer //every second create entry
			max.lines
			output
	
		Methods
			create.new.file //SensorName_YYYYMMDD_Counter.csv
			create.random.lat.lon //random num given, can be null
			write.to.file //TimeStamp, SensorId, SensorName, Key1, Value1, Key2, Value2
			timer.enacted //create line items every 1 second
			close.file //when line items reach 100, close to create new file
	
	Class- IngestorPOC.cs
		//Read completed CSV files and add line items to cloud data table (log entry for this task)
		//Run test function from TestCSVRead and delete CSV if function if true
	
		Var
			file.name //IngestorName_YYYYMMDD_Counter.txt
			sensor.file.name //SensorName_YYYYMMDD_Counter.csv
			output
			sensor.file.output
			amt.null.values	
			amt.line.read
			
		Methods
			create.new.file //IngestorName_YYYYMMDD_Counter.txt
			read.file //SensorName_YYYYMMDD_Counter.csv
			count.lines //count amount of lines in file
			count.null.values //count how many lines lat and lon values were null
			write.to.file //create log when sensor file is scanned
				“TimeStamp”: “2025-03-03T15:31:05.000Z”,
				“Source”: “SensorPOC”,
				“FileName” : “SensorPOC_20250303_101.csv”,
				“SuccessEntries”: 100, // entries that have values
				“FailedEntries”: 0, //entries that have empty/null values
				“Errors”: “”
			scan.for.file //scan to find unlocked
			close.file //when program ends, close file
	
	
	Class- TestCSVFile.cs
		//Run test that verifies all line items were correctly uploaded from CSV to data table
		//Return true is done correctly
		//Return false an error if false
	
	Class- MockAuth
		//Show Auth implemented for user usage of the app
		//Will not be functioning
	
	Class- Could database integration
		//when file from Sensor is read, log and data ran within IngesterPOC is added to a database
	
	Class- Docker
		//Create Docker for SensorPOC and IngestorPOC classes


For future improvements, I would add the testing, as stated, to ensure all files are writing, reading, and closing correctly. There is plenty of log.messages
but having test give the likelihood of logging errors minimal. 
The docker containers need to be implemented. 
Authentication for users and admin will need to be added to ensure correct usage and changes are made by the correct people. 
Deletion of csv file after read, tested that reading was correct, and the file is no longer needed. This would save on memory space, and cleaner file management.
